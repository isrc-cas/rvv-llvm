; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=riscv64 -mcpu=xiangshan-nanhu -verify-machineinstrs < %s \
; RUN:  | FileCheck -check-prefix=XS-Nanhu %s

define i64 @fuseaddwzexth64(i64 %a) nounwind {
; XS-Nanhu-LABEL: fuseaddwzexth64:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    zext.h a1, a0
; XS-Nanhu-NEXT:    slli a2, a0, 16
; XS-Nanhu-NEXT:    srli a2, a2, 16
; XS-Nanhu-NEXT:    add.uw a0, a0, a1
; XS-Nanhu-NEXT:    add a0, a0, a2
; XS-Nanhu-NEXT:    ret
    %1 = shl i64 %a, 32
    %2 = shl i64 %a, 48
    %3 = shl i64 %a, 16
    %4 = lshr i64 %1, 32
    %5 = lshr i64 %2, 48
    %6 = lshr i64 %3, 16
    %7 = add i64 %4, %5
    %8 = add i64 %7, %6
    ret i64 %8
}


define i64 @signextend64(i64 %a) nounwind {
; XS-Nanhu-LABEL: signextend64:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    sext.w a1, a0
; XS-Nanhu-NEXT:    sext.h a2, a0
; XS-Nanhu-NEXT:    slli a0, a0, 16
; XS-Nanhu-NEXT:    srai a0, a0, 16
; XS-Nanhu-NEXT:    add a1, a1, a2
; XS-Nanhu-NEXT:    add a0, a0, a1
; XS-Nanhu-NEXT:    ret
    %1 = shl i64 %a, 32
    %2 = shl i64 %a, 48
    %3 = shl i64 %a, 16
    %4 = ashr i64 %1, 32
    %5 = ashr i64 %2, 48
    %6 = ashr i64 %3, 16
    %7 = add i64 %4, %5
    %8 = add i64 %7, %6
    ret i64 %8
}

define i64 @sladd64(i64 %a,i64 %b) nounwind {
; XS-Nanhu-LABEL: sladd64:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    sh1add a1, a0, a1
; XS-Nanhu-NEXT:    slli a2, a0, 2
; XS-Nanhu-NEXT:    sh2add a0, a0, a1
; XS-Nanhu-NEXT:    sh3add a0, a0, a2
; XS-Nanhu-NEXT:    add a0, a0, a1
; XS-Nanhu-NEXT:    ret
    %1 = shl i64 %a, 1
    %2 = add i64 %1, %b
    %3 = shl i64 %a, 2
    %4 = add i64 %3, %2
    %5 = shl i64 %4, 3
    %6 = add i64 %5, %3
    %7 = add i64 %6, %2
    ret i64 %7
}

define i64 @extshift64(i64 %a,i64 %b) nounwind {
; XS-Nanhu-LABEL: extshift64:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    addi a0, a1, 32
; XS-Nanhu-NEXT:    ret
    %1 = shl i64 %a, 32
    %2 = add i64 %b, 32
    %3 = lshr i64 %1, 29
    ret i64 %2
}

define i64 @secondbyte64(i64 %a) nounwind {
; XS-Nanhu-LABEL: secondbyte64:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    srli a0, a0, 8
; XS-Nanhu-NEXT:    andi a0, a0, 255
; XS-Nanhu-NEXT:    ret
    %1 = lshr i64 %a, 8
    %2 = and i64 %1, 255
    ret i64 %2
}

define i64 @sradd64(i64 %a,i64 %b) nounwind {
; XS-Nanhu-LABEL: sradd64:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    srli a2, a0, 29
; XS-Nanhu-NEXT:    add a1, a1, a2
; XS-Nanhu-NEXT:    srli a0, a0, 30
; XS-Nanhu-NEXT:    add a2, a0, a1
; XS-Nanhu-NEXT:    srli a2, a2, 32
; XS-Nanhu-NEXT:    add a0, a0, a2
; XS-Nanhu-NEXT:    add a0, a0, a1
; XS-Nanhu-NEXT:    ret
    %1 = lshr i64 %a, 29
    %2 = add i64 %1, %b
    %3 = lshr i64 %a, 30
    %4 = add i64 %3, %2
    %5 = lshr i64 %4, 32
    %6 = add i64 %5, %3
    %7 = add i64 %6, %2
    ret i64 %7
}

define i64 @addifodd64(i64 %a,i64 %b) nounwind {
; XS-Nanhu-LABEL: addifodd64:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    andi a0, a0, 1
; XS-Nanhu-NEXT:    add a0, a0, a1
; XS-Nanhu-NEXT:    ret
    %1 = and i64 %a, 1
    %2 = add i64 %1, %b
    ret i64 %2
}

define i64 @addandextract64(i64 %a,i64 %b) nounwind {
; XS-Nanhu-LABEL: addandextract64:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    addw a0, a0, a1
; XS-Nanhu-NEXT:    andi a0, a0, 1
; XS-Nanhu-NEXT:    ret
    %1 = add i64 %a, %b
    %2 = and i64 %1, 1
    ret i64 %2
}

define i64 @addandextend(i64 %a,i64 %b) nounwind {
; XS-Nanhu-LABEL: addandextend:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    addw a0, a0, a1
; XS-Nanhu-NEXT:    zext.h a0, a0
; XS-Nanhu-NEXT:    ret
    %1 = add i64 %a, %b
    %2 = shl i64 %1, 48
    %3 = lshr i64 %2, 48
    ret i64 %3
}

define i64 @orwithlower(i64 %a,i64 %b) nounwind {
; XS-Nanhu-LABEL: orwithlower:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    or a0, a0, a1
; XS-Nanhu-NEXT:    zext.h a0, a0
; XS-Nanhu-NEXT:    ret
    %1 = or i64 %a, %b
    %2 = shl i64 %1, 48
    %3 = lshr i64 %2, 48
    ret i64 %3
}

define i64 @mul7and32(i64 %a,i64 %b) nounwind {
; XS-Nanhu-LABEL: mul7and32:
; XS-Nanhu:       # %bb.0:
; XS-Nanhu-NEXT:    andi a0, a0, 127
; XS-Nanhu-NEXT:    mul a0, a0, a1
; XS-Nanhu-NEXT:    ret
    %1 = and i64 %a, u0x7f
    %2 = mul i64 %1, %b
    ret i64 %2
}
