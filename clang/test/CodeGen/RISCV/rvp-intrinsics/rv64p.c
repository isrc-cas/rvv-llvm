// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// REQUIRES: riscv-registered-target
// RUN: %clang_cc1 -triple riscv64 -O2 -target-feature +experimental-p \
// RUN:   -emit-llvm %s -o - | FileCheck --check-prefix=CHECK-RV64 %s

typedef signed char int8x4_t __attribute((vector_size(4)));
typedef signed char int8x8_t __attribute((vector_size(8)));
typedef short int16x2_t __attribute((vector_size(4)));
typedef short int16x4_t __attribute__((vector_size(8)));
typedef short int16x8_t __attribute__((vector_size(16)));
typedef int int32x2_t __attribute__((vector_size(8)));
typedef int int32x4_t __attribute__((vector_size(16)));
typedef unsigned char uint8x4_t __attribute__((vector_size(4)));
typedef unsigned char uint8x8_t __attribute__((vector_size(8)));
typedef unsigned short uint16x2_t __attribute__((vector_size(4)));
typedef unsigned short uint16x4_t __attribute__((vector_size(8)));
typedef unsigned short uint16x8_t __attribute__((vector_size(16)));
typedef unsigned int uint32x2_t __attribute__((vector_size(8)));
typedef unsigned int uint32x4_t __attribute__((vector_size(16)));

// CHECK-RV64-LABEL: @add8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.add8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long add8(unsigned long a, unsigned long b) {
  return __rv_add8(a, b);
}

// CHECK-RV64-LABEL: @add16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.add16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long add16(unsigned long a, unsigned long b) {
  return __rv_add16(a, b);
}

// CHECK-RV64-LABEL: @ave(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ave.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long ave(long a, long b) {
  return __rv_ave(a, b);
}

// CHECK-RV64-LABEL: @bitrev(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.bitrev.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long bitrev(unsigned long a, unsigned long b) {
  return __rv_bitrev(a, b);
}

// CHECK-RV64-LABEL: @bpick(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.bpick.i64(i64 [[A:%.*]], i64 [[B:%.*]], i64 [[C:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long bpick(unsigned long a, unsigned long b, unsigned long c) {
  return __rv_bpick(a, b, c);
}

// CHECK-RV64-LABEL: @clrs8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.clrs8.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long clrs8(unsigned long a) {
  return __rv_clrs8(a);
}

// CHECK-RV64-LABEL: @clrs16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.clrs16.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long clrs16(unsigned long a) {
  return __rv_clrs16(a);
}

// CHECK-RV64-LABEL: @clrs32(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.clrs32.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long clrs32(unsigned long a) {
  return __rv_clrs32(a);
}

// CHECK-RV64-LABEL: @clz8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.clz8.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long clz8(unsigned long a) {
  return __rv_clz8(a);
}

// CHECK-RV64-LABEL: @clz16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.clz16.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long clz16(unsigned long a) {
  return __rv_clz16(a);
}

// CHECK-RV64-LABEL: @clz32(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.clz32.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long clz32(unsigned long a) {
  return __rv_clz32(a);
}

// CHECK-RV64-LABEL: @cmpeq8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.cmpeq8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long cmpeq8(unsigned long a, unsigned long b) {
  return __rv_cmpeq8(a, b);
}

// CHECK-RV64-LABEL: @cmpeq16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.cmpeq16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long cmpeq16(unsigned long a, unsigned long b) {
  return __rv_cmpeq16(a, b);
}

// CHECK-RV64-LABEL: @cras16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.cras16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long cras16(unsigned long a, unsigned long b) {
  return __rv_cras16(a, b);
}

// CHECK-RV64-LABEL: @crsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.crsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long crsa16(unsigned long a, unsigned long b) {
  return __rv_crsa16(a, b);
}

// CHECK-RV64-LABEL: @insb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.insb.i64(i64 [[A:%.*]], i64 [[B:%.*]], i64 5)
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long insb(unsigned long a, unsigned long b) {
  return __rv_insb(a, b, 5);
}

// CHECK-RV64-LABEL: @kabs8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kabs8.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kabs8(unsigned long a) {
  return __rv_kabs8(a);
}

// CHECK-RV64-LABEL: @kabs16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kabs16.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kabs16(unsigned long a) {
  return __rv_kabs16(a);
}

// CHECK-RV64-LABEL: @kabsw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kabsw.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kabsw(long a) {
  return __rv_kabsw(a);
}

// CHECK-RV64-LABEL: @kadd8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kadd8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kadd8(unsigned long a, unsigned long b) {
  return __rv_kadd8(a, b);
}

// CHECK-RV64-LABEL: @kadd16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kadd16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kadd16(unsigned long a, unsigned long b) {
  return __rv_kadd16(a, b);
}

// CHECK-RV64-LABEL: @kaddh(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kaddh.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kaddh(int a, int b) {
  return __rv_kaddh(a, b);
}

// CHECK-RV64-LABEL: @kaddw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kaddw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kaddw(int a, int b) {
  return __rv_kaddw(a, b);
}

// CHECK-RV64-LABEL: @kcras16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kcras16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kcras16(unsigned long a, unsigned long b) {
  return __rv_kcras16(a, b);
}

// CHECK-RV64-LABEL: @kcrsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kcrsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kcrsa16(unsigned long a, unsigned long b) {
  return __rv_kcrsa16(a, b);
}

// CHECK-RV64-LABEL: @kdmbb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kdmbb.i64.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kdmbb(unsigned int a, unsigned int b) {
  return __rv_kdmbb(a, b);
}

// CHECK-RV64-LABEL: @kdmbt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kdmbt.i64.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kdmbt(unsigned int a, unsigned int b) {
  return __rv_kdmbt(a, b);
}

// CHECK-RV64-LABEL: @kdmtt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kdmtt.i64.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kdmtt(unsigned int a, unsigned int b) {
  return __rv_kdmtt(a, b);
}

// CHECK-RV64-LABEL: @kdmabb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kdmabb.i64.i64(i64 [[T:%.*]], i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kdmabb(long t, unsigned int a, unsigned int b) {
  return __rv_kdmabb(t, a, b);
}

// CHECK-RV64-LABEL: @kdmabt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kdmabt.i64.i64(i64 [[T:%.*]], i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kdmabt(long t, unsigned int a, unsigned int b) {
  return __rv_kdmabt(t, a, b);
}

// CHECK-RV64-LABEL: @kdmatt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kdmatt.i64.i64(i64 [[T:%.*]], i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kdmatt(long t, unsigned int a, unsigned int b) {
  return __rv_kdmatt(t, a, b);
}

// CHECK-RV64-LABEL: @khm8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.khm8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long khm8(unsigned long a, unsigned long b) {
  return __rv_khm8(a, b);
}

// CHECK-RV64-LABEL: @khmx8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.khmx8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long khmx8(unsigned long a, unsigned long b) {
  return __rv_khmx8(a, b);
}

// CHECK-RV64-LABEL: @khm16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.khm16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long khm16(unsigned long a, unsigned long b) {
  return __rv_khm16(a, b);
}

// CHECK-RV64-LABEL: @khmx16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.khmx16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long khmx16(unsigned long a, unsigned long b) {
  return __rv_khmx16(a, b);
}

// CHECK-RV64-LABEL: @khmbb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.khmbb.i64.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long khmbb(unsigned int a, unsigned int b) {
  return __rv_khmbb(a, b);
}

// CHECK-RV64-LABEL: @khmbt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.khmbt.i64.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long khmbt(unsigned int a, unsigned int b) {
  return __rv_khmbt(a, b);
}

// CHECK-RV64-LABEL: @khmtt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.khmtt.i64.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long khmtt(unsigned int a, unsigned int b) {
  return __rv_khmtt(a, b);
}

// CHECK-RV64-LABEL: @kmabb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmabb.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmabb(long t, unsigned long a, unsigned long b) {
  return __rv_kmabb(t, a, b);
}

// CHECK-RV64-LABEL: @kmabt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmabt.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmabt(long t, unsigned long a, unsigned long b) {
  return __rv_kmabt(t, a, b);
}

// CHECK-RV64-LABEL: @kmatt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmatt.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmatt(long t, unsigned long a, unsigned long b) {
  return __rv_kmatt(t, a, b);
}

// CHECK-RV64-LABEL: @kmada(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmada.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmada(long t, unsigned long a, unsigned long b) {
  return __rv_kmada(t, a, b);
}

// CHECK-RV64-LABEL: @kmaxda(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmaxda.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmaxda(long t, unsigned long a, unsigned long b) {
  return __rv_kmaxda(t, a, b);
}

// CHECK-RV64-LABEL: @kmads(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmads.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmads(long t, unsigned long a, unsigned long b) {
  return __rv_kmads(t, a, b);
}

// CHECK-RV64-LABEL: @kmadrs(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmadrs.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmadrs(long t, unsigned long a, unsigned long b) {
  return __rv_kmadrs(t, a, b);
}

// CHECK-RV64-LABEL: @kmaxds(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmaxds.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmaxds(long t, unsigned long a, unsigned long b) {
  return __rv_kmaxds(t, a, b);
}

// CHECK-RV64-LABEL: @kmda(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmda.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmda(unsigned long a, unsigned long b) {
  return __rv_kmda(a, b);
}

// CHECK-RV64-LABEL: @kmxda(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmxda.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmxda(unsigned long a, unsigned long b) {
  return __rv_kmxda(a, b);
}

// CHECK-RV64-LABEL: @kmmac(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmac.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmac(long t, long a, long b) {
  return __rv_kmmac(t, a, b);
}

// CHECK-RV64-LABEL: @kmmac_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmac.u.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmac_u(long t, long a, long b) {
  return __rv_kmmac_u(t, a, b);
}

// CHECK-RV64-LABEL: @kmmawb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmawb.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmawb(long t, unsigned long a, unsigned long b) {
  return __rv_kmmawb(t, a, b);
}

// CHECK-RV64-LABEL: @kmmawb_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmawb.u.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmawb_u(long t, unsigned long a, unsigned long b) {
  return __rv_kmmawb_u(t, a, b);
}

// CHECK-RV64-LABEL: @kmmawb2(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmawb2.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmawb2(long t, unsigned long a, unsigned long b) {
  return __rv_kmmawb2(t, a, b);
}

// CHECK-RV64-LABEL: @kmmawb2_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmawb2.u.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmawb2_u(long t, unsigned long a, unsigned long b) {
  return __rv_kmmawb2_u(t, a, b);
}

// CHECK-RV64-LABEL: @kmmawt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmawt.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmawt(long t, unsigned long a, unsigned long b) {
  return __rv_kmmawt(t, a, b);
}

// CHECK-RV64-LABEL: @kmmawt_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmawt.u.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmawt_u(long t, unsigned long a, unsigned long b) {
  return __rv_kmmawt_u(t, a, b);
}

// CHECK-RV64-LABEL: @kmmawt2(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmawt2.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmawt2(long t, unsigned long a, unsigned long b) {
  return __rv_kmmawt2(t, a, b);
}

// CHECK-RV64-LABEL: @kmmawt2_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmawt2.u.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmawt2_u(long t, unsigned long a, unsigned long b) {
  return __rv_kmmawt2_u(t, a, b);
}

// CHECK-RV64-LABEL: @kmmsb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmsb.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmsb(long t, long a, long b) {
  return __rv_kmmsb(t, a, b);
}

// CHECK-RV64-LABEL: @kmmsb_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmsb.u.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmsb_u(long t, long a, long b) {
  return __rv_kmmsb_u(t, a, b);
}

// CHECK-RV64-LABEL: @kmmwb2(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmwb2.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmwb2(long a, unsigned long b) {
  return __rv_kmmwb2(a, b);
}

// CHECK-RV64-LABEL: @kmmwb2_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmwb2.u.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmwb2_u(long a, unsigned long b) {
  return __rv_kmmwb2_u(a, b);
}

// CHECK-RV64-LABEL: @kmmwt2(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmwt2.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmwt2(long a, unsigned long b) {
  return __rv_kmmwt2(a, b);
}

// CHECK-RV64-LABEL: @kmmwt2_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmmwt2.u.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmmwt2_u(long a, unsigned long b) {
  return __rv_kmmwt2_u(a, b);
}

// CHECK-RV64-LABEL: @kmsda(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmsda.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmsda(long t, unsigned long a, unsigned long b) {
  return __rv_kmsda(t, a, b);
}

// CHECK-RV64-LABEL: @kmsxda(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kmsxda.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kmsxda(long t, unsigned long a, unsigned long b) {
  return __rv_kmsxda(t, a, b);
}

// CHECK-RV64-LABEL: @ksllw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ksllw.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long ksllw(long a, unsigned int b) {
  return __rv_ksllw(a, b);
}

// CHECK-RV64-LABEL: @ksll8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ksll8.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ksll8(unsigned long a, unsigned int b) {
  return __rv_ksll8(a, b);
}

// CHECK-RV64-LABEL: @ksll16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ksll16.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ksll16(unsigned long a, unsigned int b) {
  return __rv_ksll16(a, b);
}

// CHECK-RV64-LABEL: @kslra8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kslra8.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kslra8(unsigned long a, int b) {
  return __rv_kslra8(a, b);
}

// CHECK-RV64-LABEL: @kslra8_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kslra8.u.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kslra8_u(unsigned long a, int b) {
  return __rv_kslra8_u(a, b);
}

// CHECK-RV64-LABEL: @kslra16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kslra16.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kslra16(unsigned long a, int b) {
  return __rv_kslra16(a, b);
}

// CHECK-RV64-LABEL: @kslra16_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kslra16.u.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kslra16_u(unsigned long a, int b) {
  return __rv_kslra16_u(a, b);
}

// CHECK-RV64-LABEL: @kslraw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kslraw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kslraw(int a, int b) {
  return __rv_kslraw(a, b);
}

// CHECK-RV64-LABEL: @kslraw_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kslraw.u.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kslraw_u(int a, int b) {
  return __rv_kslraw_u(a, b);
}

// CHECK-RV64-LABEL: @kstas16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kstas16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kstas16(unsigned long a, unsigned long b) {
  return __rv_kstas16(a, b);
}

// CHECK-RV64-LABEL: @kstsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kstsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long kstsa16(unsigned long a, unsigned long b) {
  return __rv_kstsa16(a, b);
}

// CHECK-RV64-LABEL: @ksub8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ksub8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ksub8(unsigned long a, unsigned long b) {
  return __rv_ksub8(a, b);
}

// CHECK-RV64-LABEL: @ksub16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ksub16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ksub16(unsigned long a, unsigned long b) {
  return __rv_ksub16(a, b);
}

// CHECK-RV64-LABEL: @ksubh(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ksubh.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long ksubh(int a, int b) {
  return __rv_ksubh(a, b);
}

// CHECK-RV64-LABEL: @ksubw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ksubw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long ksubw(int a, int b) {
  return __rv_ksubw(a, b);
}

// CHECK-RV64-LABEL: @kwmmul(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kwmmul.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kwmmul(long a, long b) {
  return __rv_kwmmul(a, b);
}

// CHECK-RV64-LABEL: @kwmmul_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.kwmmul.u.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long kwmmul_u(long a, long b) {
  return __rv_kwmmul_u(a, b);
}

// CHECK-RV64-LABEL: @maxw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.maxw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long maxw(int a, int b) {
  return __rv_maxw(a, b);
}

// CHECK-RV64-LABEL: @minw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.minw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long minw(int a, int b) {
  return __rv_minw(a, b);
}

// CHECK-RV64-LABEL: @pbsad(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.pbsad.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long pbsad(unsigned long a, unsigned long b) {
  return __rv_pbsad(a, b);
}

// CHECK-RV64-LABEL: @pbsada(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.pbsada.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long pbsada(unsigned long t, unsigned long a, unsigned long b) {
  return __rv_pbsada(t, a, b);
}

// CHECK-RV64-LABEL: @pkbb16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.pkbb16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long pkbb16(unsigned long a, unsigned long b) {
  return __rv_pkbb16(a, b);
}

// CHECK-RV64-LABEL: @pkbt16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.pkbt16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long pkbt16(unsigned long a, unsigned long b) {
  return __rv_pkbt16(a, b);
}

// CHECK-RV64-LABEL: @pktt16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.pktt16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long pktt16(unsigned long a, unsigned long b) {
  return __rv_pktt16(a, b);
}

// CHECK-RV64-LABEL: @pktb16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.pktb16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long pktb16(unsigned long a, unsigned long b) {
  return __rv_pktb16(a, b);
}

// CHECK-RV64-LABEL: @radd8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.radd8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long radd8(unsigned long a, unsigned long b) {
  return __rv_radd8(a, b);
}

// CHECK-RV64-LABEL: @radd16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.radd8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long radd16(unsigned long a, unsigned long b) {
  return __rv_radd8(a, b);
}

// CHECK-RV64-LABEL: @raddw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.raddw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long raddw(int a, int b) {
  return __rv_raddw(a, b);
}

// CHECK-RV64-LABEL: @rcras16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.rcras16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long rcras16(unsigned long a, unsigned long b) {
  return __rv_rcras16(a, b);
}

// CHECK-RV64-LABEL: @rcrsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.rcrsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long rcrsa16(unsigned long a, unsigned long b) {
  return __rv_rcrsa16(a, b);
}

// CHECK-RV64-LABEL: @rstas16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.rstas16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long rstas16(unsigned long a, unsigned long b) {
  return __rv_rstas16(a, b);
}

// CHECK-RV64-LABEL: @rstsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.rstsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long rstsa16(unsigned long a, unsigned long b) {
  return __rv_rstsa16(a, b);
}

// CHECK-RV64-LABEL: @rsub8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.rsub8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long rsub8(unsigned long a, unsigned long b) {
  return __rv_rsub8(a, b);
}

// CHECK-RV64-LABEL: @rsub16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.rsub16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long rsub16(unsigned long a, unsigned long b) {
  return __rv_rsub16(a, b);
}

// CHECK-RV64-LABEL: @rsubw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.rsubw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long rsubw(int a, int b) {
  return __rv_rsubw(a, b);
}

// CHECK-RV64-LABEL: @sclip8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sclip8.i64.i64(i64 [[A:%.*]], i64 7)
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sclip8(unsigned long a) {
  return __rv_sclip8(a, 7);
}

// CHECK-RV64-LABEL: @sclip16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sclip16.i64.i64(i64 [[A:%.*]], i64 8)
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sclip16(unsigned long a) {
  return __rv_sclip16(a, 8);
}

// CHECK-RV64-LABEL: @sclip32(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sclip32.i64.i64(i64 [[A:%.*]], i64 9)
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long sclip32(long a) {
  return __rv_sclip32(a, 9);
}

// CHECK-RV64-LABEL: @scmple8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.scmple8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long scmple8(unsigned long a, unsigned long b) {
  return __rv_scmple8(a, b);
}

// CHECK-RV64-LABEL: @scmple16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.scmple16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long scmple16(unsigned long a, unsigned long b) {
  return __rv_scmple16(a, b);
}

// CHECK-RV64-LABEL: @scmplt8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.scmplt8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long scmplt8(unsigned long a, unsigned long b) {
  return __rv_scmplt8(a, b);
}

// CHECK-RV64-LABEL: @scmplt16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.scmplt16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long scmplt16(unsigned long a, unsigned long b) {
  return __rv_scmplt16(a, b);
}

// CHECK-RV64-LABEL: @sll8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sll8.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sll8(unsigned long a, unsigned int b) {
  return __rv_sll8(a, b);
}

// CHECK-RV64-LABEL: @sll16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sll16.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sll16(unsigned long a, unsigned int b) {
  return __rv_sll16(a, b);
}

// CHECK-RV64-LABEL: @smaqa(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smaqa.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smaqa(long t, unsigned long a, unsigned long b) {
  return __rv_smaqa(t, a, b);
}

// CHECK-RV64-LABEL: @smaqa_su(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smaqa.su.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smaqa_su(long t, unsigned long a, unsigned long b) {
  return __rv_smaqa_su(t, a, b);
}

// CHECK-RV64-LABEL: @smax8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smax8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long smax8(unsigned long a, unsigned long b) {
  return __rv_smax8(a, b);
}

// CHECK-RV64-LABEL: @smax16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smax16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long smax16(unsigned long a, unsigned long b) {
  return __rv_smax16(a, b);
}

// CHECK-RV64-LABEL: @smbb16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smbb16.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smbb16(unsigned long a, unsigned long b) {
  return __rv_smbb16(a, b);
}

// CHECK-RV64-LABEL: @smbt16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smbt16.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smbt16(unsigned long a, unsigned long b) {
  return __rv_smbt16(a, b);
}

// CHECK-RV64-LABEL: @smtt16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smtt16.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smtt16(unsigned long a, unsigned long b) {
  return __rv_smtt16(a, b);
}

// CHECK-RV64-LABEL: @smds(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smds.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smds(unsigned long a, unsigned long b) {
  return __rv_smds(a, b);
}

// CHECK-RV64-LABEL: @smdrs(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smdrs.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smdrs(unsigned long a, unsigned long b) {
  return __rv_smdrs(a, b);
}

// CHECK-RV64-LABEL: @smxds(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smxds.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smxds(unsigned long a, unsigned long b) {
  return __rv_smxds(a, b);
}

// CHECK-RV64-LABEL: @smin8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smin8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long smin8(unsigned long a, unsigned long b) {
  return __rv_smin8(a, b);
}

// CHECK-RV64-LABEL: @smin16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smin16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long smin16(unsigned long a, unsigned long b) {
  return __rv_smin16(a, b);
}

// CHECK-RV64-LABEL: @smmul(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smmul.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smmul(long a, long b) {
  return __rv_smmul(a, b);
}

// CHECK-RV64-LABEL: @smmul_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smmul.u.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smmul_u(long a, long b) {
  return __rv_smmul_u(a, b);
}

// CHECK-RV64-LABEL: @smmwb(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smmwb.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smmwb(long a, long b) {
  return __rv_smmwb(a, b);
}

// CHECK-RV64-LABEL: @smmwb_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smmwb.u.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smmwb_u(long a, long b) {
  return __rv_smmwb_u(a, b);
}

// CHECK-RV64-LABEL: @smmwt(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smmwt.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smmwt(long a, long b) {
  return __rv_smmwt(a, b);
}

// CHECK-RV64-LABEL: @smmwt_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.smmwt.u.i64.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long smmwt_u(long a, long b) {
  return __rv_smmwt_u(a, b);
}

// CHECK-RV64-LABEL: @sra_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sra.u.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long sra_u(long a, unsigned int b) {
  return __rv_sra_u(a, b);
}

// CHECK-RV64-LABEL: @sra8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sra8.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sra8(unsigned long a, unsigned int b) {
  return __rv_sra8(a, b);
}

// CHECK-RV64-LABEL: @sra8_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sra8.u.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sra8_u(unsigned long a, unsigned int b) {
  return __rv_sra8_u(a, b);
}

// CHECK-RV64-LABEL: @sra16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sra16.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sra16(unsigned long a, unsigned int b) {
  return __rv_sra16(a, b);
}

// CHECK-RV64-LABEL: @sra16_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sra16.u.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sra16_u(unsigned long a, unsigned int b) {
  return __rv_sra16_u(a, b);
}

// CHECK-RV64-LABEL: @srl8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.srl8.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long srl8(unsigned long a, unsigned int b) {
  return __rv_srl8(a, b);
}

// CHECK-RV64-LABEL: @srl8_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.srl8.u.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long srl8_u(unsigned long a, unsigned int b) {
  return __rv_srl8_u(a, b);
}

// CHECK-RV64-LABEL: @srl16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.srl16.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long srl16(unsigned long a, unsigned int b) {
  return __rv_srl16(a, b);
}

// CHECK-RV64-LABEL: @srl16_u(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.srl16.u.i64.i64(i64 [[A:%.*]], i64 [[CONV]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long srl16_u(unsigned long a, unsigned int b) {
  return __rv_srl16_u(a, b);
}

// CHECK-RV64-LABEL: @stas16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.stas16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long stas16(unsigned long a, unsigned long b) {
  return __rv_stas16(a, b);
}

// CHECK-RV64-LABEL: @stsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.stsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long stsa16(unsigned long a, unsigned long b) {
  return __rv_stsa16(a, b);
}

// CHECK-RV64-LABEL: @sub8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sub8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sub8(unsigned long a, unsigned long b) {
  return __rv_sub8(a, b);
}

// CHECK-RV64-LABEL: @sub16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sub16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sub16(unsigned long a, unsigned long b) {
  return __rv_sub16(a, b);
}

// CHECK-RV64-LABEL: @sunpkd810(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sunpkd810.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sunpkd810(unsigned long a) {
  return __rv_sunpkd810(a);
}

// CHECK-RV64-LABEL: @sunpkd820(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sunpkd820.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sunpkd820(unsigned long a) {
  return __rv_sunpkd820(a);
}

// CHECK-RV64-LABEL: @sunpkd830(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sunpkd830.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sunpkd830(unsigned long a) {
  return __rv_sunpkd830(a);
}

// CHECK-RV64-LABEL: @sunpkd831(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sunpkd831.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sunpkd831(unsigned long a) {
  return __rv_sunpkd831(a);
}

// CHECK-RV64-LABEL: @sunpkd832(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.sunpkd832.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long sunpkd832(unsigned long a) {
  return __rv_sunpkd832(a);
}

// CHECK-RV64-LABEL: @swap8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.swap8.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long swap8(unsigned long a) {
  return __rv_swap8(a);
}

// CHECK-RV64-LABEL: @swap16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.swap16.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long swap16(unsigned long a) {
  return __rv_swap16(a);
}

// CHECK-RV64-LABEL: @uclip8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uclip8.i64.i64(i64 [[A:%.*]], i64 7)
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uclip8(unsigned long a) {
  return __rv_uclip8(a, 7);
}

// CHECK-RV64-LABEL: @uclip16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uclip16.i64.i64(i64 [[A:%.*]], i64 8)
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uclip16(unsigned long a) {
  return __rv_uclip16(a, 8);
}

// CHECK-RV64-LABEL: @uclip32(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uclip32.i64.i64(i64 [[A:%.*]], i64 9)
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long uclip32(long a) {
  return __rv_uclip32(a, 9);
}

// CHECK-RV64-LABEL: @ucmple8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ucmple8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ucmple8(unsigned long a, unsigned long b) {
  return __rv_ucmple8(a, b);
}

// CHECK-RV64-LABEL: @ucmple16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ucmple16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ucmple16(unsigned long a, unsigned long b) {
  return __rv_ucmple16(a, b);
}

// CHECK-RV64-LABEL: @ucmplt8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ucmplt8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ucmplt8(unsigned long a, unsigned long b) {
  return __rv_ucmplt8(a, b);
}

// CHECK-RV64-LABEL: @ucmplt16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ucmplt16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ucmplt16(unsigned long a, unsigned long b) {
  return __rv_ucmplt16(a, b);
}

// CHECK-RV64-LABEL: @ukadd8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ukadd8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ukadd8(unsigned long a, unsigned long b) {
  return __rv_ukadd8(a, b);
}

// CHECK-RV64-LABEL: @ukadd16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ukadd16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ukadd16(unsigned long a, unsigned long b) {
  return __rv_ukadd16(a, b);
}

// CHECK-RV64-LABEL: @ukaddh(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ukaddh.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long ukaddh(int a, int b) {
  return __rv_ukaddh(a, b);
}

// CHECK-RV64-LABEL: @ukaddw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = sext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = sext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ukaddw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
long ukaddw(int a, int b) {
  return __rv_ukaddw(a, b);
}

// CHECK-RV64-LABEL: @ukcras16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ukcras16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ukcras16(unsigned long a, unsigned long b) {
  return __rv_ukcras16(a, b);
}

// CHECK-RV64-LABEL: @ukcrsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ukcrsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ukcrsa16(unsigned long a, unsigned long b) {
  return __rv_ukcrsa16(a, b);
}

// CHECK-RV64-LABEL: @ukstas16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ukstas16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ukstas16(unsigned long a, unsigned long b) {
  return __rv_ukstas16(a, b);
}

// CHECK-RV64-LABEL: @ukstsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ukstsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ukstsa16(unsigned long a, unsigned long b) {
  return __rv_ukstsa16(a, b);
}

// CHECK-RV64-LABEL: @uksub8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uksub8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uksub8(unsigned long a, unsigned long b) {
  return __rv_uksub8(a, b);
}

// CHECK-RV64-LABEL: @uksub16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uksub16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uksub16(unsigned long a, unsigned long b) {
  return __rv_uksub16(a, b);
}

// CHECK-RV64-LABEL: @uksubh(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uksubh.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uksubh(unsigned int a, unsigned int b) {
  return __rv_uksubh(a, b);
}

// CHECK-RV64-LABEL: @uksubw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uksubw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uksubw(unsigned int a, unsigned int b) {
  return __rv_uksubw(a, b);
}

// CHECK-RV64-LABEL: @umaqa(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.umaqa.i64.i64(i64 [[T:%.*]], i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long umaqa(unsigned long t, unsigned long a, unsigned long b) {
  return __rv_umaqa(t, a, b);
}

// CHECK-RV64-LABEL: @umax8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.umax8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long umax8(unsigned long a, unsigned long b) {
  return __rv_umax8(a, b);
}

// CHECK-RV64-LABEL: @umax16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.umax16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long umax16(unsigned long a, unsigned long b) {
  return __rv_umax16(a, b);
}

// CHECK-RV64-LABEL: @umin8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.umin8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long umin8(unsigned long a, unsigned long b) {
  return __rv_umin8(a, b);
}

// CHECK-RV64-LABEL: @umin16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.umin16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long umin16(unsigned long a, unsigned long b) {
  return __rv_umin16(a, b);
}

// CHECK-RV64-LABEL: @uradd8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uradd8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uradd8(unsigned long a, unsigned long b) {
  return __rv_uradd8(a, b);
}

// CHECK-RV64-LABEL: @uradd16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uradd8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uradd16(unsigned long a, unsigned long b) {
  return __rv_uradd8(a, b);
}

// CHECK-RV64-LABEL: @uraddw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.uraddw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long uraddw(unsigned int a, unsigned int b) {
  return __rv_uraddw(a, b);
}

// CHECK-RV64-LABEL: @urcras16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.urcras16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long urcras16(unsigned long a, unsigned long b) {
  return __rv_urcras16(a, b);
}

// CHECK-RV64-LABEL: @urcrsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.urcrsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long urcrsa16(unsigned long a, unsigned long b) {
  return __rv_urcrsa16(a, b);
}

// CHECK-RV64-LABEL: @urstas16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.urstas16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long urstas16(unsigned long a, unsigned long b) {
  return __rv_urstas16(a, b);
}

// CHECK-RV64-LABEL: @urstsa16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.urstsa16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long urstsa16(unsigned long a, unsigned long b) {
  return __rv_urstsa16(a, b);
}

// CHECK-RV64-LABEL: @ursub8(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ursub8.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ursub8(unsigned long a, unsigned long b) {
  return __rv_ursub8(a, b);
}

// CHECK-RV64-LABEL: @ursub16(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ursub16.i64(i64 [[A:%.*]], i64 [[B:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ursub16(unsigned long a, unsigned long b) {
  return __rv_ursub16(a, b);
}

// CHECK-RV64-LABEL: @ursubw(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[CONV:%.*]] = zext i32 [[A:%.*]] to i64
// CHECK-RV64-NEXT:    [[CONV1:%.*]] = zext i32 [[B:%.*]] to i64
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.ursubw.i64(i64 [[CONV]], i64 [[CONV1]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long ursubw(unsigned int a, unsigned int b) {
  return __rv_ursubw(a, b);
}

// CHECK-RV64-LABEL: @zunpkd810(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.zunpkd810.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long zunpkd810(unsigned long a) {
  return __rv_zunpkd810(a);
}

// CHECK-RV64-LABEL: @zunpkd820(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.zunpkd820.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long zunpkd820(unsigned long a) {
  return __rv_zunpkd820(a);
}

// CHECK-RV64-LABEL: @zunpkd830(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.zunpkd830.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long zunpkd830(unsigned long a) {
  return __rv_zunpkd830(a);
}

// CHECK-RV64-LABEL: @zunpkd831(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.zunpkd831.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long zunpkd831(unsigned long a) {
  return __rv_zunpkd831(a);
}

// CHECK-RV64-LABEL: @zunpkd832(
// CHECK-RV64-NEXT:  entry:
// CHECK-RV64-NEXT:    [[TMP0:%.*]] = tail call i64 @llvm.riscv.zunpkd832.i64(i64 [[A:%.*]])
// CHECK-RV64-NEXT:    ret i64 [[TMP0]]
//
unsigned long zunpkd832(unsigned long a) {
  return __rv_zunpkd832(a);
}
